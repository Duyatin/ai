{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "#from torchvision.transforms import transforms\n",
    "\n",
    "from lib.cfg import *\n",
    "from lib.dataloader import get_calcification_data_index, DatasetThyroid\n",
    "from lib.model import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data train size:  694\n",
      "Data test size:  174\n"
     ]
    }
   ],
   "source": [
    "# Dataloader init\n",
    "df_data_index = get_calcification_data_index()\n",
    "\n",
    "idx_train, idx_test = train_test_split(\n",
    "    list(range(len(df_data_index))),\n",
    "    test_size=0.2, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print('Data train size: ', len(idx_train))\n",
    "print('Data test size: ', len(idx_test))\n",
    "df_data_index_train = df_data_index.iloc[idx_train]\n",
    "df_data_index_test = df_data_index.iloc[idx_test]\n",
    "\n",
    "# ~3G RAM per image\n",
    "batch_size_train = 2\n",
    "dataloader_train = DataLoader(\n",
    "    DatasetThyroid(df_data_index_train, image_transform, mask_transform, True), \n",
    "    batch_size=batch_size_train,  \n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "batch_size_test = 4\n",
    "dataloader_test = DataLoader(\n",
    "    DatasetThyroid(df_data_index_test, image_transform, mask_transform, False), \n",
    "    batch_size=batch_size_test,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "dataloader_all = DataLoader(\n",
    "    DatasetThyroid(df_data_index, image_transform, mask_transform, False), \n",
    "    batch_size=batch_size_train, \n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net init\n",
    "unet = Unet(3, 1).cuda()\n",
    "unet.load_state_dict(torch.load('./unet_calcification.pth'))\n",
    "\n",
    "optimizer = optim.Adam(unet.parameters(), lr=1e-3)\n",
    "class_weights = torch.tensor([1.7]).cuda()\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/347.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347.0 [02:49<00:00,  2.04it/s]\n",
      "  0%|          | 0/43.5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: 0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:15,  2.92it/s]                          \n",
      "  0%|          | 0/347.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Test Loss: 0.014\n",
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347.0 [02:49<00:00,  2.04it/s]\n",
      "  0%|          | 0/43.5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:15,  2.91it/s]                          \n",
      "  0%|          | 0/347.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Test Loss: 0.006\n",
      "Epoch 2/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347.0 [02:49<00:00,  2.04it/s]\n",
      "  0%|          | 0/43.5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:15,  2.91it/s]                          \n",
      "  0%|          | 0/347.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Test Loss: 0.005\n",
      "Epoch 3/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347.0 [02:49<00:00,  2.05it/s]\n",
      "  0%|          | 0/43.5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:15,  2.92it/s]                          \n",
      "  0%|          | 0/347.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Test Loss: 0.004\n",
      "Epoch 4/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347.0 [02:49<00:00,  2.04it/s]\n",
      "  0%|          | 0/43.5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:15,  2.91it/s]                          \n",
      "  0%|          | 0/347.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Test Loss: 0.003\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347.0 [02:49<00:00,  2.04it/s]\n",
      "  0%|          | 0/43.5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:15,  2.91it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Test Loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "epoch_start = 0\n",
    "num_epochs = 6\n",
    "\n",
    "for epoch in range(epoch_start, epoch_start+num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, epoch_start+num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Train loss\n",
    "    train_loss = 0\n",
    "    train_step = 0\n",
    "    for img, mask, _, _ in tqdm(dataloader_train, total=len(dataloader_train.dataset)/batch_size_train):\n",
    "        train_step += 1\n",
    "        img = img.cuda()\n",
    "        mask = mask.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        mask_pred = unet(img)\n",
    "        loss = criterion(mask_pred, mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss_avg = train_loss/train_step\n",
    "    print(\"Epoch %d | Train Loss: %0.3f\" % (epoch, train_loss_avg))\n",
    "    \n",
    "    # Test loss\n",
    "    test_loss = 0\n",
    "    test_step = 0\n",
    "    for img, mask, _, _ in tqdm(dataloader_test, total=len(dataloader_test.dataset)/batch_size_test):\n",
    "        test_step += 1\n",
    "        with torch.no_grad():\n",
    "            img = img.cuda()\n",
    "            mask = mask.cuda()\n",
    "            mask_pred = unet(img)\n",
    "            loss = criterion(mask_pred, mask)\n",
    "            test_loss += loss.item()\n",
    "    test_loss_avg = test_loss/test_step\n",
    "    print(\"Epoch %d | Test Loss: %0.3f\" % (epoch, test_loss_avg))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.save(unet.state_dict(), './unet_calcification.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict mask and calculate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434.0 [01:20<00:00,  5.40it/s]\n"
     ]
    }
   ],
   "source": [
    "df_cal_features = []\n",
    "batch_size_test = 2\n",
    "\n",
    "for image, _, lesion_mask_gt_batch, img_id in tqdm(dataloader_all, total=len(dataloader_all.dataset)/batch_size_test):\n",
    "    with torch.no_grad():\n",
    "        mask_pred_batch = unet(image.cuda())\n",
    "\n",
    "    for i in range(batch_size_test):\n",
    "        mask_pred = mask_pred_batch[i].squeeze().cpu().numpy()\n",
    "        lesion_mask_gt = lesion_mask_gt_batch[i].squeeze()\n",
    "\n",
    "        mask_pred_roi = mask_pred*lesion_mask_gt.numpy()\n",
    "        cal_mask_binary = np.zeros([512,512])\n",
    "        cal_mask_binary[mask_pred_roi >= 0.5] = 1\n",
    "        rescaling_factor = 500/512/10\n",
    "        \n",
    "        connected_region = measure.label(cal_mask_binary, connectivity=2)\n",
    "        region_props = measure.regionprops(connected_region)\n",
    "        \n",
    "        cal_length = list()\n",
    "        for props in region_props:\n",
    "            cal_length.append(props.major_axis_length*rescaling_factor)\n",
    "\n",
    "        cal_length = np.array(cal_length)\n",
    "        cal_micro = cal_length[cal_length < 2]\n",
    "\n",
    "        if len(cal_micro):\n",
    "            micro_length_min = min(cal_micro)\n",
    "            micro_length_mean = np.mean(cal_micro)\n",
    "        else:\n",
    "            micro_length_min = np.float('nan')\n",
    "            micro_length_mean = np.float('nan')\n",
    "\n",
    "        obj = {\n",
    "            'pid': int(img_id[i]),\n",
    "            'count_all': len(cal_length),\n",
    "            'count_mirco': len(cal_micro),\n",
    "            'micro_length_min': micro_length_min,\n",
    "            'micro_length_mean': micro_length_mean\n",
    "        }\n",
    "        \n",
    "        df_cal_features.append(obj)\n",
    "        \n",
    "df_cal_features = pd.DataFrame(df_cal_features)\n",
    "df_cal_features = df_cal_features.sort_values(['pid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
